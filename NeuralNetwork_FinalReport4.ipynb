{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork_FinalReport4.ipynb 的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "urWRJH-Q_GMQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb996338-e9de-426b-d7f3-e2d67578c11a"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# ==================================================================== #\n",
        "# author: Yung-Hsin Chen                                               #\n",
        "# copyright: Copyright 2020, Pneumonia Diagnosis                       #                                                            \n",
        "# ==================================================================== #\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDi24no1_TaE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61a7a6ee-99fc-4171-cd9d-f152b1b34b2f"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import VGG16\n",
        "from keras import layers, models\n",
        "import json\n",
        "import pandas as pd\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True' # for MAC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYL53QOKrquH"
      },
      "source": [
        "### $\\underline{Loading\\;and\\;Storing\\;Data}$\n",
        "##### - Classes: pneumonia, normal\n",
        "##### - Train (228x228x100), Validation (228x228x16), Test (228x228x5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFFVXlvQ_VRS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f8de8cfe-0575-44cc-a5fd-36ae1e961a0e"
      },
      "source": [
        "imgX = imgY = 224\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.15,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        ")\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Pneumonia_ML/chest_x_ray'\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    path + '/data/train',\n",
        "    target_size = (imgX, imgY),\n",
        "    batch_size = 50,#5216\n",
        "    class_mode = \"binary\",\n",
        "    shuffle = True\n",
        ")\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    path +'/data/val',\n",
        "    target_size = (imgX, imgY),\n",
        "    batch_size = 16,\n",
        "    class_mode = \"binary\",\n",
        "    shuffle = False\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    path +'/data/test',\n",
        "    target_size = (imgX, imgY),\n",
        "    batch_size = 5,#624\n",
        "    class_mode = \"binary\",\n",
        "    shuffle = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5226 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zxfdiuZr_4E"
      },
      "source": [
        "### $\\underline{Neural\\;Network\\;Layers}$\n",
        "##### - Conv2D\n",
        "##### - Maxpooling2D\n",
        "##### - Conv2D\n",
        "##### - Maxpooling2D\n",
        "##### - Conv2D\n",
        "##### - Dense (Sigmoid)\n",
        "##### - Dropout (0.5)\n",
        "##### - Dense (Sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snu9t2emRbq1"
      },
      "source": [
        "# pretrain = tf.keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = False, input_tensor = tf.keras.layers.Input(shape=(imgX, imgY, 3)))\n",
        "# pretrain.trainable = False\n",
        "conv1 = tf.keras.layers.Conv2D(128, (3, 3), activation='sigmoid', padding = 'same')\n",
        "# conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='sigmoid', padding = 'same')\n",
        "pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "conv2 = tf.keras.layers.Conv2D(256, (3, 3), activation='sigmoid', padding = 'same')\n",
        "pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "conv3 = tf.keras.layers.Conv2D(256, (3, 3), activation='sigmoid', padding = 'same')\n",
        "flatten = tf.keras.layers.Flatten()\n",
        "dense1 = tf.keras.layers.Dense(256, activation='sigmoid')\n",
        "drop1 = tf.keras.layers.Dropout(0.5)\n",
        "dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "model = tf.keras.Sequential([tf.keras.layers.Input(shape=(imgX, imgY, 3)), conv1, pool1, conv2, pool2, conv3, flatten, dense1, drop1, dense2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CllM-xwlBW9j"
      },
      "source": [
        "conv1.trainable = False\n",
        "pool1.trainable = False\n",
        "conv2.trainable = False\n",
        "pool2.trainable = False\n",
        "conv3.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h54WjQO5_bYU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "dff374ad-3397-4235-dac5-4c52c78da004"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 128)     3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 112, 112, 256)     295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 802816)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               205521152 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 206,410,241\n",
            "Trainable params: 205,521,409\n",
            "Non-trainable params: 888,832\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcu-6xPospay"
      },
      "source": [
        "### $\\underline{Training}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZBX1UKJ_ddO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e6584797-dd28-44ec-cc51-2a91b12932e4"
      },
      "source": [
        "print(\"START COMPILING\")\n",
        "model.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.RMSprop(), metrics=[tf.keras.metrics.binary_crossentropy,'accuracy'])\n",
        "print(\"START FITTING\")\n",
        "history = model.fit(train_generator, epochs = 3, validation_data = test_generator)\n",
        "score = model.evaluate(test_generator, verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "START COMPILING\n",
            "START FITTING\n",
            "Epoch 1/3\n",
            "105/105 [==============================] - 1459s 14s/step - loss: 1.3704 - binary_crossentropy: 1.3704 - accuracy: 0.7413 - val_loss: 0.7056 - val_binary_crossentropy: 0.7056 - val_accuracy: 0.6250\n",
            "Epoch 2/3\n",
            "105/105 [==============================] - 1458s 14s/step - loss: 0.5910 - binary_crossentropy: 0.5910 - accuracy: 0.7392 - val_loss: 0.7001 - val_binary_crossentropy: 0.7001 - val_accuracy: 0.6250\n",
            "Epoch 3/3\n",
            "105/105 [==============================] - 1460s 14s/step - loss: 0.5887 - binary_crossentropy: 0.5887 - accuracy: 0.7409 - val_loss: 0.6861 - val_binary_crossentropy: 0.6861 - val_accuracy: 0.6250\n",
            "Test loss: 0.6861472725868225\n",
            "Test accuracy: 0.625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB93uZiMstO4"
      },
      "source": [
        "### $\\underline{Saving\\;History}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0j_TQP0UPBy"
      },
      "source": [
        "history_file = pd.DataFrame(history.history)\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Pneumonia_ML/chest_x_ray'\n",
        "with open('path + /history2.json', 'w') as fh:\n",
        "    history_file.to_json(fh)\n",
        "history_json                 = pd.read_json('history.json')\n",
        "accuracy                     = history_json['accuracy']\n",
        "val_accuracy                 = history_json['val_accuracy']\n",
        "loss                         = history_json['loss']\n",
        "val_loss                     = history_json['val_loss']\n",
        "categorical_crossentropy     = history_json['categorical_crossentropy']\n",
        "val_categorical_crossentropy = history_json['val_categorical_crossentropy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FZDbjTYs2Ee"
      },
      "source": [
        "### $\\underline{Plot\\;of\\;accuracy}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyi7C18As2U6"
      },
      "source": [
        "plt.plot(accuracy)\n",
        "plt.plot(val_accuracy)\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.savefig('model-images/accuracy.png',dpi=160);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}